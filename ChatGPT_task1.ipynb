{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import openai \n",
    "import ast\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U13740</td>\n",
       "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U91836</td>\n",
       "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U73700</td>\n",
       "      <td>N10732 N25792 N7563 N21087 N41087 N5445 N60384...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User                                                 ID\n",
       "0  U13740  N55189 N42782 N34694 N45794 N18445 N63302 N104...\n",
       "1  U91836  N31739 N6072 N63045 N23979 N35656 N43353 N8129...\n",
       "2  U73700  N10732 N25792 N7563 N21087 N41087 N5445 N60384..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data with user behaviors\n",
    "behaviors = pd.read_csv(\"MIND/behaviorsTEST.tsv\",sep='\\t',  header=None)\n",
    "behaviors.columns =['User', 'Time', 'ID', 'Impressions'] \n",
    "behaviors = behaviors.drop(['Time', 'Impressions'], axis=1)\n",
    "behaviors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N42782</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>Three takeaways from Yankees' ALCS Game 5 vict...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N34694</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N45794</td>\n",
       "      <td>news</td>\n",
       "      <td>newscrime</td>\n",
       "      <td>Four flight attendants were arrested in Miami'...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N18445</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_ncaa</td>\n",
       "      <td>Michigan sends breakup tweet to Notre Dame as ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID Category    SubCategory  \\\n",
       "0  N55189       tv         tvnews   \n",
       "1  N42782   sports   baseball_mlb   \n",
       "2  N34694       tv         tvnews   \n",
       "3  N45794     news      newscrime   \n",
       "4  N18445   sports  football_ncaa   \n",
       "\n",
       "                                             Content Sentiment  \n",
       "0  'Wheel Of Fortune' Guest Delivers Hilarious, O...  Positive  \n",
       "1  Three takeaways from Yankees' ALCS Game 5 vict...  Positive  \n",
       "2  Rosie O'Donnell: Barbara Walters Isn't 'Up to ...  Positive  \n",
       "3  Four flight attendants were arrested in Miami'...  Positive  \n",
       "4  Michigan sends breakup tweet to Notre Dame as ...  Positive  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"sentiment_analysis/sentiment_TEST.csv\") #document with user interactions\n",
    "news = news.iloc[:, 1:] \n",
    "news = news.drop(['Content_emb'], axis=1)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_related_content(user):\n",
    "    user_row = behaviors[behaviors['User'] == user]\n",
    "    \n",
    "    if user_row.empty:\n",
    "        return [(\"No data found for user\", user)]\n",
    "    \n",
    "    user_ids = user_row['ID'].iloc[0].split()\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        id_row = news[news['ID'] == user_id]\n",
    "        \n",
    "        if not id_row.empty:\n",
    "            content = id_row['Content'].iloc[0]\n",
    "            result.append((user_id, content))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_news(n):\n",
    "    random_news = random.sample(list(news.itertuples(index=False, name=None)), n)\n",
    "    return [(news[0], news[3]) for news in random_news]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "openai.api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chat with GPT\n",
    "def chat_with_chatgpt(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    message = response['choices'][0]['message']['content'].strip()\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_task1 (user, n_news):\n",
    "    user_output = get_user_related_content(user)\n",
    "    random_news = get_random_news (n_news)\n",
    "    formatted_random_news = [f'{item[0]}: {item[1]}' for item in random_news]\n",
    "    formatted_user_output = [f'{item[0]}: {item[1]}' for item in user_output]\n",
    "    user_prompt = (f\"The user has interacted with the following items (in no particular order): {formatted_user_output}. Basing on user interactions, sort items from this list {formatted_random_news} in order of priority, from highest to lowest. Output format: a python list with news index (e.g., N12345). Do not explain the reason or include any other words.\")\n",
    "    \n",
    "    chatbot_response = chat_with_chatgpt(user_prompt)\n",
    "    \n",
    "    # Remove leading and trailing whitespaces and newline characters\n",
    "    cleaned_string = chatbot_response.strip()\n",
    "\n",
    "    # Use ast.literal_eval to safely evaluate the string as a literal expression\n",
    "    result_list = ast.literal_eval(cleaned_string)\n",
    "    set1 = set(formatted_user_output)\n",
    "    set2 = set(result_list[:10])\n",
    "    if not set1.intersection(set2):\n",
    "        print(\"The lists do not intercross (have no common elements).\")\n",
    "    else:\n",
    "        print(\"The lists intercross (have common elements).\")\n",
    "    return (result_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U13740']\n"
     ]
    }
   ],
   "source": [
    "# n is the number of random user IDs you want to select\n",
    "n = 1\n",
    "# Select n random user IDs from the DataFrame\n",
    "random_user_ids = behaviors['User'].sample(n).tolist()\n",
    "print(random_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'U13740'\n",
    "n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists do not intercross (have no common elements).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['N13131',\n",
       " 'N58715',\n",
       " 'N47346',\n",
       " 'N48722',\n",
       " 'N29739',\n",
       " 'N3142',\n",
       " 'N59685',\n",
       " 'N7023',\n",
       " 'N51570',\n",
       " 'N21623']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_task1(user_input, 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_news_ids(user_id,):\n",
    "    # Find the row corresponding to the user ID\n",
    "    user_row = behaviors[behaviors['User'] == user_id]\n",
    "\n",
    "    # If the user ID exists in the DataFrame\n",
    "    if not user_row.empty:\n",
    "        # Split the IDs from the 'ID' column\n",
    "        news_ids = user_row['ID'].iloc[0].split()\n",
    "        return news_ids\n",
    "    else:\n",
    "        print(f\"User ID {user_id} not found in the DataFrame.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_correlation(user, n_news):\n",
    "    user_output = user_news_ids(user)\n",
    "    user_news_df = news[news['ID'].isin(user_output)]\n",
    "    categ_counts_user = user_news_df['Category'].value_counts()\n",
    "    total_counts = user_news_df['Category'].value_counts().sum()\n",
    "    user_ration = categ_counts_user/total_counts\n",
    "    \n",
    "    list_of_recommebdations_t1 = gpt_task1(user, n_news)\n",
    "    user_recom_df = news[news['ID'].isin(list_of_recommebdations_t1)]\n",
    "    categ_counts_recom = user_recom_df['Category'].value_counts()\n",
    "    ratio_recom = categ_counts_recom/10\n",
    "    \n",
    "    merged_df = pd.concat([ratio_recom, user_ration], axis=1, sort=False).fillna(0)\n",
    "    merged_df.columns = ['recommend', 'profiles']\n",
    "    \n",
    "    try:\n",
    "        correlation, p_value = pearsonr(merged_df['recommend'], merged_df['profiles'])\n",
    "    except ValueError as e:\n",
    "         print(\"An error occurred:\", e)\n",
    "         print(\"Skipping correlation calculation due to insufficient data.\")\n",
    "    \n",
    "    #print(categ_counts_user)\n",
    "    print(merged_df)\n",
    "    print(correlation, p_value )\n",
    "    \n",
    "    return correlation, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists do not intercross (have no common elements).\n",
      "              recommend  profiles\n",
      "Category                         \n",
      "news                0.4  0.333333\n",
      "sports              0.3  0.222222\n",
      "lifestyle           0.1  0.111111\n",
      "health              0.1  0.000000\n",
      "foodanddrink        0.1  0.000000\n",
      "tv                  0.0  0.222222\n",
      "movies              0.0  0.111111\n",
      "0.6085989058527204 0.1469936618489937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6085989058527204, 0.1469936618489937)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_correlation(user_input, n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subcategory correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subcategory_correlation(user, n_news):\n",
    "    user_output = user_news_ids(user)\n",
    "    user_news_df = news[news['ID'].isin(user_output)]\n",
    "    categ_counts_user = user_news_df['SubCategory'].value_counts()\n",
    "    total_counts = user_news_df['SubCategory'].value_counts().sum()\n",
    "    user_ratio = categ_counts_user/total_counts\n",
    "    \n",
    "    list_of_recommebdations_t1 = gpt_task1(user, n_news)\n",
    "    user_recom_df = news[news['ID'].isin(list_of_recommebdations_t1)]\n",
    "    categ_counts_recom = user_recom_df['SubCategory'].value_counts()\n",
    "    ratio_recom = categ_counts_recom/10\n",
    "    \n",
    "    merged_df = pd.concat([ratio_recom, user_ratio], axis=1, sort=False).fillna(0)\n",
    "    merged_df.columns = ['recommend', 'profiles']\n",
    "    \n",
    "    try:\n",
    "        correlation, p_value = pearsonr(merged_df['recommend'], merged_df['profiles'])\n",
    "    except ValueError as e:\n",
    "         print(\"An error occurred:\", e)\n",
    "         print(\"Skipping correlation calculation due to insufficient data.\")\n",
    "    \n",
    "    print(merged_df)\n",
    "    print(correlation, p_value )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists do not intercross (have no common elements).\n",
      "                        recommend  profiles\n",
      "SubCategory                                \n",
      "newsus                        0.3  0.000000\n",
      "markets                       0.1  0.000000\n",
      "lifestyle-news-feature        0.1  0.000000\n",
      "travelnews                    0.1  0.000000\n",
      "newscrime                     0.1  0.111111\n",
      "football_nfl                  0.1  0.000000\n",
      "finance-real-estate           0.1  0.000000\n",
      "lifestylehomeandgarden        0.1  0.000000\n",
      "tvnews                        0.0  0.222222\n",
      "newspolitics                  0.0  0.222222\n",
      "baseball_mlb                  0.0  0.111111\n",
      "football_ncaa                 0.0  0.111111\n",
      "lifestylebuzz                 0.0  0.111111\n",
      "movienews                     0.0  0.111111\n",
      "-0.6791130292870468 0.007563221953400732\n"
     ]
    }
   ],
   "source": [
    "subcategory_correlation(user_input, n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_correlation(user, n_news):\n",
    "    user_output = user_news_ids(user)\n",
    "    user_news_df = news[news['ID'].isin(user_output)]\n",
    "    categ_counts_user = user_news_df['Sentiment'].value_counts()\n",
    "    total_counts = user_news_df['Sentiment'].value_counts().sum()\n",
    "    user_ratio = categ_counts_user/total_counts\n",
    "    \n",
    "    list_of_recommebdations_t1 = gpt_task1(user, n_news)\n",
    "    user_recom_df = news[news['ID'].isin(list_of_recommebdations_t1)]\n",
    "    categ_counts_recom = user_recom_df['Sentiment'].value_counts()\n",
    "    ratio_recom = categ_counts_recom/10\n",
    "    \n",
    "    merged_df = pd.concat([ratio_recom, user_ratio], axis=1, sort=False).fillna(0)\n",
    "    merged_df.columns = ['recommend', 'profiles']\n",
    "    \n",
    "    try:\n",
    "        correlation, p_value = pearsonr(merged_df['recommend'], merged_df['profiles'])\n",
    "    except ValueError as e:\n",
    "         print(\"An error occurred:\", e)\n",
    "         print(\"Skipping correlation calculation due to insufficient data.\")\n",
    "    \n",
    "    print(merged_df)\n",
    "    print(correlation, p_value )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists do not intercross (have no common elements).\n",
      "           recommend  profiles\n",
      "Sentiment                     \n",
      "Positive         0.7  0.888889\n",
      "Negative         0.1  0.111111\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "sentiment_correlation(user_input, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
