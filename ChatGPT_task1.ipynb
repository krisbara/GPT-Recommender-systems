{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import openai \n",
    "import ast\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U13740</td>\n",
       "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U91836</td>\n",
       "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U73700</td>\n",
       "      <td>N10732 N25792 N7563 N21087 N41087 N5445 N60384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U34670</td>\n",
       "      <td>N45729 N2203 N871 N53880 N41375 N43142 N33013 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U8125</td>\n",
       "      <td>N10078 N56514 N14904 N33740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User                                                 ID\n",
       "0  U13740  N55189 N42782 N34694 N45794 N18445 N63302 N104...\n",
       "1  U91836  N31739 N6072 N63045 N23979 N35656 N43353 N8129...\n",
       "2  U73700  N10732 N25792 N7563 N21087 N41087 N5445 N60384...\n",
       "3  U34670  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...\n",
       "4   U8125                        N10078 N56514 N14904 N33740"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data with user behaviors\n",
    "behaviors = pd.read_csv(\"MIND/behaviors.tsv\",sep='\\t',  header=None)\n",
    "behaviors.columns =['User', 'Time', 'ID', 'Impressions'] \n",
    "behaviors = behaviors.drop(['Time', 'Impressions'], axis=1)\n",
    "behaviors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55528</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N19639</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat These seemingly ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N61837</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N53526</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N38324</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID   Category      SubCategory  \\\n",
       "0  N55528  lifestyle  lifestyleroyals   \n",
       "1  N19639     health       weightloss   \n",
       "2  N61837       news        newsworld   \n",
       "3  N53526     health           voices   \n",
       "4  N38324     health          medical   \n",
       "\n",
       "                                             Content Sentiment  \n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...  Positive  \n",
       "1  50 Worst Habits For Belly Fat These seemingly ...  Negative  \n",
       "2  The Cost of Trump's Aid Freeze in the Trenches...  Negative  \n",
       "3  I Was An NBA Wife. Here's How It Affected My M...   Neutral  \n",
       "4  How to Get Rid of Skin Tags, According to a De...  Positive  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"sentiment_analysis/sentiment_final.csv\") #document with user interactions\n",
    "news = news.iloc[:, 1:] \n",
    "news = news.drop(['Content_emb'], axis=1)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_related_content(user):\n",
    "    user_row = behaviors[behaviors['User'] == user]\n",
    "    \n",
    "    if user_row.empty:\n",
    "        return [(\"No data found for user\", user)]\n",
    "    \n",
    "    user_ids = user_row['ID'].iloc[0].split()\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        id_row = news[news['ID'] == user_id]\n",
    "        \n",
    "        if not id_row.empty:\n",
    "            content = id_row['Content'].iloc[0]\n",
    "            result.append((user_id, content))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_news(n):\n",
    "    random_news = random.sample(list(news.itertuples(index=False, name=None)), n)\n",
    "    return [(news[0], news[3]) for news in random_news]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chat with GPT\n",
    "def chat_with_chatgpt(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    message = response['choices'][0]['message']['content'].strip()\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_task1 (user, n_news):\n",
    "    user_output = get_user_related_content(user)\n",
    "    random_news = get_random_news (n_news)\n",
    "    formatted_random_news = [f'{item[0]}: {item[1]}' for item in random_news]\n",
    "    formatted_user_output = [f'{item[0]}: {item[1]}' for item in user_output]\n",
    "    user_prompt = (f\"The user has interacted with the following items (in no particular order): {formatted_user_output}. Basing on user interactions, sort items from this list {formatted_random_news} in order of priority, from highest to lowest. Output format: a python list with news index (e.g., N12345). Do not explain the reason or include any other words.\")\n",
    "    \n",
    "    chatbot_response = chat_with_chatgpt(user_prompt)\n",
    "    \n",
    "    # Remove leading and trailing whitespaces and newline characters\n",
    "    cleaned_string = chatbot_response.strip()\n",
    "\n",
    "    # Use ast.literal_eval to safely evaluate the string as a literal expression\n",
    "    result_list = ast.literal_eval(cleaned_string)\n",
    "    #print(formatted_random_news)\n",
    "    #print(formatted_user_output)\n",
    "    #print([f'{item[0]}' for item in user_output])\n",
    "    #print([f'{item[0]}' for item in random_news])\n",
    "    set1 = set(formatted_user_output)\n",
    "    set2 = set(result_list[:10])\n",
    "    if not set1.intersection(set2):\n",
    "        print(\"The lists do not intercross (have no common elements).\")\n",
    "    else:\n",
    "        print(\"The lists intercross (have common elements).\")\n",
    "    return (result_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U31215', 'U67536', 'U43995', 'U2226', 'U71029', 'U53409', 'U79696', 'U59324', 'U92123', 'U58065', 'U88851', 'U81716', 'U72672', 'U77817', 'U11182']\n"
     ]
    }
   ],
   "source": [
    "# n is the number of random user IDs you want to select\n",
    "n = 15\n",
    "# Select n random user IDs from the DataFrame\n",
    "random_user_ids = behaviors['User'].sample(n).tolist()\n",
    "print(random_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'U53409'\n",
    "n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists do not intercross (have no common elements).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['N11177',\n",
       " 'N49365',\n",
       " 'N18109',\n",
       " 'N995',\n",
       " 'N63906',\n",
       " 'N16606',\n",
       " 'N60615',\n",
       " 'N21242',\n",
       " 'N36751',\n",
       " 'N24298']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_task1(user_input, 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_news_ids(user_id,):\n",
    "    # Find the row corresponding to the user ID\n",
    "    user_row = behaviors[behaviors['User'] == user_id]\n",
    "\n",
    "    # If the user ID exists in the DataFrame\n",
    "    if not user_row.empty:\n",
    "        # Split the IDs from the 'ID' column\n",
    "        news_ids = user_row['ID'].iloc[0].split()\n",
    "        return news_ids\n",
    "    else:\n",
    "        print(f\"User ID {user_id} not found in the DataFrame.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_correlation(user, n_news):\n",
    "    user_output = user_news_ids(user)\n",
    "    user_news_df = news[news['ID'].isin(user_output)]\n",
    "    categ_counts_user = user_news_df['Category'].value_counts()\n",
    "    \n",
    "    list_of_recommebdations_t1 = gpt_task1(user, n_news)\n",
    "    user_recom_df = news[news['ID'].isin(list_of_recommebdations_t1)]\n",
    "    categ_counts_recom = user_recom_df['Category'].value_counts()\n",
    "    \n",
    "    merged_df = pd.concat([categ_counts_recom, categ_counts_user], axis=1, sort=False).fillna(0)\n",
    "    merged_df.columns = ['recommend', 'profiles']\n",
    "    \n",
    "    try:\n",
    "        correlation, p_value = pearsonr(merged_df['recommend'], merged_df['profiles'])\n",
    "    except ValueError as e:\n",
    "         print(\"An error occurred:\", e)\n",
    "         print(\"Skipping correlation calculation due to insufficient data.\")\n",
    "    \n",
    "    #print(categ_counts_user)\n",
    "    #print(categ_counts_recom)\n",
    "    print(correlation, p_value )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists do not intercross (have no common elements).\n",
      "0.1840871005899612 0.6625553527654022\n"
     ]
    }
   ],
   "source": [
    "category_correlation(user_input, n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subcategory correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subcategory_correlation(user, n_news):\n",
    "    user_output = user_news_ids(user)\n",
    "    user_news_df = news[news['ID'].isin(user_output)]\n",
    "    categ_counts_user = user_news_df['SubCategory'].value_counts()\n",
    "    \n",
    "    list_of_recommebdations_t1 = gpt_task1(user, n_news)\n",
    "    user_recom_df = news[news['ID'].isin(list_of_recommebdations_t1)]\n",
    "    categ_counts_recom = user_recom_df['SubCategory'].value_counts()\n",
    "    \n",
    "    merged_df = pd.concat([categ_counts_recom, categ_counts_user], axis=1, sort=False).fillna(0)\n",
    "    merged_df.columns = ['recommend', 'profiles']\n",
    "    \n",
    "    try:\n",
    "        correlation, p_value = pearsonr(merged_df['recommend'], merged_df['profiles'])\n",
    "    except ValueError as e:\n",
    "         print(\"An error occurred:\", e)\n",
    "         print(\"Skipping correlation calculation due to insufficient data.\")\n",
    "    \n",
    "    print(categ_counts_user)\n",
    "    print(categ_counts_recom)\n",
    "    print(correlation, p_value )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists do not intercross (have no common elements).\n",
      "newspolitics           11\n",
      "restaurantsandnews      3\n",
      "foodnews                2\n",
      "newsus                  1\n",
      "lifestyledidyouknow     1\n",
      "markets                 1\n",
      "elections-2020-us       1\n",
      "viral                   1\n",
      "football_ncaa           1\n",
      "basketball_nba          1\n",
      "Name: SubCategory, dtype: int64\n",
      "recipes                     1\n",
      "lifestylebuzz               1\n",
      "autosresearch               1\n",
      "basketball_nba              1\n",
      "more_sports                 1\n",
      "newsscienceandtechnology    1\n",
      "travelarticle               1\n",
      "newsoffbeat                 1\n",
      "weathertopstories           1\n",
      "newstrends                  1\n",
      "Name: SubCategory, dtype: int64\n",
      "-0.47966935209423317 0.03768668881974604\n"
     ]
    }
   ],
   "source": [
    "subcategory_correlation(user_input, n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_correlation(user, n_news):\n",
    "    user_output = user_news_ids(user)\n",
    "    user_news_df = news[news['ID'].isin(user_output)]\n",
    "    categ_counts_user = user_news_df['Sentiment'].value_counts()\n",
    "    \n",
    "    list_of_recommebdations_t1 = gpt_task1(user, n_news)\n",
    "    user_recom_df = news[news['ID'].isin(list_of_recommebdations_t1)]\n",
    "    categ_counts_recom = user_recom_df['Sentiment'].value_counts()\n",
    "    \n",
    "    merged_df = pd.concat([categ_counts_recom, categ_counts_user], axis=1, sort=False).fillna(0)\n",
    "    merged_df.columns = ['recommend', 'profiles']\n",
    "    \n",
    "    try:\n",
    "        correlation, p_value = pearsonr(merged_df['recommend'], merged_df['profiles'])\n",
    "    except ValueError as e:\n",
    "         print(\"An error occurred:\", e)\n",
    "         print(\"Skipping correlation calculation due to insufficient data.\")\n",
    "    \n",
    "    print(categ_counts_user)\n",
    "    print(categ_counts_recom)\n",
    "    print(correlation, p_value )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists do not intercross (have no common elements).\n",
      "Positive    11\n",
      "Negative     8\n",
      "Neutral      4\n",
      "Name: Sentiment, dtype: int64\n",
      "Negative    4\n",
      "Neutral     3\n",
      "Positive    3\n",
      "Name: Sentiment, dtype: int64\n",
      "0.08219949365267865 0.9476110671783534\n"
     ]
    }
   ],
   "source": [
    "sentiment_correlation(user_input, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
